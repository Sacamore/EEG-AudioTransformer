{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/data1/byzhao/EEG-AudioTransformer/utils.py'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import imp\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "imp.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "公共变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_path = r'./feat/words'\n",
    "pts = ['sub-%02d'%i for i in range(1,11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg = dict()\n",
    "audio = dict()\n",
    "word = dict()\n",
    "for pt in pts:\n",
    "    folder_path = os.path.join(words_path,f'{pt}')\n",
    "    word[pt] = []\n",
    "    eeg[pt] = []\n",
    "    audio[pt] = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        word_info = np.load(os.path.join(folder_path,filename),allow_pickle=True)\n",
    "        word[pt].append(word_info.item()['label'])\n",
    "        eeg[pt].append(word_info.item()['eeg'])\n",
    "        audio[pt].append(word_info.item()['audio'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-01: hij 100 (594, 127) (9280,)\n",
      "sub-02: door 100 (829, 127) (12960,)\n",
      "sub-03: te 100 (492, 127) (7680,)\n",
      "sub-04: al 100 (727, 115) (11360,)\n",
      "sub-05: nog 100 (727, 60) (11360,)\n",
      "sub-06: om 100 (809, 127) (12640,)\n",
      "sub-07: de 100 (491, 127) (7680,)\n",
      "sub-08: maantje 100 (901, 54) (14080,)\n",
      "sub-09: vier 100 (717, 117) (11200,)\n",
      "sub-10: veel 95 (532, 122) (8320,)\n"
     ]
    }
   ],
   "source": [
    "for pt in pts:\n",
    "    print(f'{pt}:',word[pt][0],len(eeg[pt]),eeg[pt][0].shape,audio[pt][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 0.025\n",
    "frameshift = 0.005\n",
    "eeg_sample_rate = 1024\n",
    "audio_sameple_rate = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取高频eeg信号和音频信号的梅尔频谱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pt in pts:\n",
    "    for i in range(len(eeg[pt])):\n",
    "        eeg[pt][i] = utils.extractHG(eeg[pt][i],eeg_sample_rate,windowLength=window_length,frameshift=frameshift)\n",
    "        audio[pt][i] = utils.extractMelSpecs(audio[pt][i],audio_sameple_rate,windowLength=window_length,frameshift=frameshift)\n",
    "        if audio[pt][i].shape[0]!=eeg[pt][i].shape[0]:\n",
    "            minlen = min(audio[pt][i].shape[0],eeg[pt][i].shape[0])\n",
    "            audio[pt][i] = audio[pt][i][:minlen,:]\n",
    "            eeg[pt][i] = eeg[pt][i][:minlen,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-01: hij 100 (111, 127) (111, 23)\n",
      "sub-02: door 100 (156, 127) (156, 23)\n",
      "sub-03: te 100 (91, 127) (91, 23)\n",
      "sub-04: al 100 (136, 115) (136, 23)\n",
      "sub-05: nog 100 (136, 60) (136, 23)\n",
      "sub-06: om 100 (153, 127) (153, 23)\n",
      "sub-07: de 100 (90, 127) (90, 23)\n",
      "sub-08: maantje 100 (170, 54) (170, 23)\n",
      "sub-09: vier 100 (135, 117) (135, 23)\n",
      "sub-10: veel 95 (98, 122) (98, 23)\n"
     ]
    }
   ],
   "source": [
    "for pt in pts:\n",
    "    print(f'{pt}:',word[pt][0],len(eeg[pt]),eeg[pt][0].shape,audio[pt][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = pts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拼接方便后续处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def concateData(pt):\n",
    "total_data = np.array(eeg[pt][0])\n",
    "total_label = np.array(audio[pt][0])\n",
    "for i in range(len(eeg[pt])):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    total_data = np.concatenate((total_data,eeg[pt][i]),axis=0)\n",
    "    total_label = np.concatenate((total_label,audio[pt][i]),axis=0)\n",
    "    # np.save(os.path.join('feat',f'{pt}_data.npy'),total_data)\n",
    "    # np.save(os.path.join('feat',f'{pt}_label.npy'),total_label)\n",
    "    # print(total_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z均值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14605, 127)\n",
      "[ 9.66860329 10.39320445  9.23300435  8.3650588   9.15385251  9.23856046\n",
      "  8.97066423  9.34830402  8.49646346  8.32958059  8.57679341  8.29289333\n",
      "  8.36476925  8.84106281  8.95595069  8.68060027  7.88845709  6.86665788\n",
      "  6.51924201  6.19771169  6.45267324  5.87137127  3.54546015]\n",
      "[6.1012631  6.98797618 6.48217311 6.53079611 6.80194787 6.55231325\n",
      " 6.47250046 5.85198999 5.49127502 5.18706556 5.62838955 5.5433698\n",
      " 5.61552868 5.80438955 5.72948746 6.01277679 7.09042082 7.02468877\n",
      " 7.32906112 7.88003409 8.02584928 6.58314508 3.84818796]\n"
     ]
    }
   ],
   "source": [
    "# 随机打乱数据索引\n",
    "indices = np.random.permutation(total_data.shape[0])\n",
    "\n",
    "# 计算划分索引\n",
    "split_index = int(total_data.shape[0] * 0.9)\n",
    "\n",
    "# 划分数据集\n",
    "train_indices = indices[:split_index]\n",
    "test_indices = indices[split_index:]\n",
    "\n",
    "# 获取训练集和测试集数据\n",
    "train_data = total_data[train_indices]\n",
    "train_label = total_label[train_indices]\n",
    "test_data = total_data[test_indices]\n",
    "test_label = total_label[test_indices]\n",
    "\n",
    "train_data_mean = np.mean(train_data)\n",
    "train_data_std = np.std(train_data)\n",
    "\n",
    "train_label_mean = np.mean(train_label)\n",
    "train_label_std = np.std(train_label)\n",
    "\n",
    "\n",
    "train_data = (train_data-train_data_mean)/train_data_std\n",
    "test_data = (test_data-train_data_mean)/train_data_std\n",
    "\n",
    "# train_label = (train_label-train_label_mean)/train_label_std\n",
    "# test_label = (test_label- train_label_std)/train_label_std\n",
    "\n",
    "print(train_data.shape)\n",
    "# print(train_data[0])\n",
    "# print(train_data[1])\n",
    "print(train_label[0])\n",
    "print(train_label[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'transformer' from '/data1/byzhao/EEG-AudioTransformer/transformer.py'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import transformer\n",
    "imp.reload(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 23\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "epochs = 1000\n",
    "print_interval = 5\n",
    "lr = 0.00002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "input_dim = total_data.shape[1]\n",
    "output_dim = total_label.shape[1]\n",
    "d_model = 256\n",
    "nhead = 4\n",
    "n_layer =6\n",
    "tensor_type = torch.cuda.FloatTensor\n",
    "\n",
    "# log_write = open(f\"./log/log_{pt}.txt\", \"w\") \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = transformer.Model(\n",
    "    input_dim=input_dim,\n",
    "    output_dim=output_dim,\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    n_layer=n_layer\n",
    ").to(device)\n",
    "\n",
    "# criterion = nn.MSELoss(reduction='mean').to(device)\n",
    "criterion = nn.L1Loss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr,betas=(b1,b2))\n",
    "\n",
    "print(input_dim,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.from_numpy(train_data)\n",
    "train_label = torch.from_numpy(train_label)\n",
    "test_data = torch.from_numpy(test_data).to(device).type(tensor_type)\n",
    "test_label = torch.from_numpy(test_label).to(device).type(tensor_type)\n",
    "\n",
    "train_dataset = TensorDataset(train_data,train_label)\n",
    "# test_dataset = TensorDataset(test_data,test_label)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True,pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(f'./logs/{pt}')\n",
    "\n",
    "writer.add_graph(model,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 1000/1000 [20:09<00:00,  1.21s/it, average loss=0.374, test loss=0.3993194]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm.trange(epochs, desc=f\"Epochs\")\n",
    "\n",
    "for e in pbar:\n",
    "    model.train()\n",
    "    aver_loss= 0\n",
    "    for _, (data, label) in enumerate(train_dataloader):\n",
    "        data = data.to(device)\n",
    "        data = data.type(tensor_type)\n",
    "        label = label.to(device)\n",
    "        label = label.type(tensor_type)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, label)\n",
    "        aver_loss+=loss.detach().cpu().numpy()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # if (e + 1) % print_interval == 0:\n",
    "    model.eval()\n",
    "    test_outputs = model(test_data)\n",
    "    test_loss = criterion(test_outputs, test_label).detach().cpu().numpy()\n",
    "    aver_loss = aver_loss/len(train_dataloader)\n",
    "    pbar.set_postfix({'average loss':aver_loss,'test loss':test_loss})\n",
    "    writer.add_scalar('average loss',aver_loss,e)\n",
    "    writer.add_scalar('test loss',test_loss,e)\n",
    "    # log_write.write(f'{e}\\t\\t{aver_loss}\\t\\t{test_loss}\\n')\n",
    "    # log_write.flush()\n",
    "\n",
    "torch.save(model.state_dict(), f'./res/{pt}_model.pth')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.8912926  7.8354187  7.1075716 ...  9.470028   8.355508   5.39604  ]\n",
      " [ 9.175585  10.351564  10.124961  ...  3.817961   3.1157362  1.6826704]\n",
      " [11.175567  12.045138  12.403337  ...  6.6445494  5.9737263  3.0142045]\n",
      " ...\n",
      " [ 4.6593966  5.338602   4.806968  ...  5.707938   5.2142453  3.0851104]\n",
      " [ 8.389989   9.372262   8.715365  ...  7.4262714  6.9215603  4.4180436]\n",
      " [ 9.569234  10.742181   9.771005  ...  4.087042   3.5551336  1.9723558]]\n",
      "[[ 6.239411   7.645665   7.3586335 ... 10.303515   8.433252   5.2470865]\n",
      " [ 8.861689  10.334457  10.338662  ...  3.8817415  3.092787   1.7568482]\n",
      " [11.29953   12.10925   12.6056185 ...  6.7364388  6.302524   2.7365558]\n",
      " ...\n",
      " [ 4.8163075  5.3071556  5.580255  ...  6.352319   5.737907   3.558425 ]\n",
      " [ 8.618947   9.813481   9.242043  ...  6.9368     6.650194   4.489153 ]\n",
      " [10.447141  11.541962   9.942531  ...  3.8754747  3.4008098  1.8305255]]\n"
     ]
    }
   ],
   "source": [
    "test_outputs = model(test_data)\n",
    "print(test_outputs.detach().cpu().numpy())\n",
    "print(test_label.detach().cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
