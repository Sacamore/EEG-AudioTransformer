{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "公共变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_path = r'./feat/words'\n",
    "pts = ['sub-%02d'%i for i in range(1,11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg = dict()\n",
    "audio = dict()\n",
    "word = dict()\n",
    "for pt in pts:\n",
    "    folder_path = os.path.join(words_path,f'{pt}')\n",
    "    word[pt] = []\n",
    "    eeg[pt] = []\n",
    "    audio[pt] = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        word_info = np.load(os.path.join(folder_path,filename),allow_pickle=True)\n",
    "        word[pt].append(word_info.item()['label'])\n",
    "        eeg[pt].append(word_info.item()['eeg'])\n",
    "        audio[pt].append(word_info.item()['audio'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-01: helft 100 (856, 127) (13376,)\n",
      "sub-02: ook 100 (512, 127) (8000,)\n",
      "sub-03: buurt 100 (726, 127) (11346,)\n",
      "sub-04: vogeltje 100 (1044, 115) (16320,)\n",
      "sub-05: verlost 100 (901, 60) (14080,)\n",
      "sub-06: hoe 100 (474, 127) (7405,)\n",
      "sub-07: zanddak 100 (1017, 127) (15899,)\n",
      "sub-08: de 100 (358, 54) (5599,)\n",
      "sub-09: tak 100 (696, 117) (10880,)\n",
      "sub-10: vijf 95 (367, 122) (5732,)\n"
     ]
    }
   ],
   "source": [
    "for pt in pts:\n",
    "    print(f'{pt}:',word[pt][0],len(eeg[pt]),eeg[pt][0].shape,audio[pt][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 0.025\n",
    "frameshift = 0.005\n",
    "eeg_sample_rate = 1024\n",
    "audio_sameple_rate = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取高频eeg信号和音频信号的梅尔频谱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pt in pts:\n",
    "    for i in range(len(eeg[pt])):\n",
    "        eeg[pt][i] = utils.extractHG(eeg[pt][i],eeg_sample_rate,windowLength=window_length,frameshift=frameshift)\n",
    "        audio[pt][i] = utils.extractMelSpecs(audio[pt][i],audio_sameple_rate,windowLength=window_length,frameshift=frameshift)\n",
    "        if audio[pt][i].shape[0]!=eeg[pt][i].shape[0]:\n",
    "            minlen = min(audio[pt][i].shape[0],eeg[pt][i].shape[0])\n",
    "            audio[pt][i] = audio[pt][i][:minlen,:]\n",
    "            eeg[pt][i] = eeg[pt][i][:minlen,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-01: helft 100 (162, 127) (162, 23)\n",
      "sub-02: ook 100 (95, 127) (95, 23)\n",
      "sub-03: buurt 100 (136, 127) (136, 23)\n",
      "sub-04: vogeltje 100 (198, 115) (198, 23)\n",
      "sub-05: verlost 100 (170, 60) (170, 23)\n",
      "sub-06: hoe 100 (87, 127) (87, 23)\n",
      "sub-07: zanddak 100 (193, 127) (193, 23)\n",
      "sub-08: de 100 (64, 54) (64, 23)\n",
      "sub-09: tak 100 (130, 117) (130, 23)\n",
      "sub-10: vijf 95 (66, 122) (66, 23)\n"
     ]
    }
   ],
   "source": [
    "for pt in pts:\n",
    "    print(f'{pt}:',word[pt][0],len(eeg[pt]),eeg[pt][0].shape,audio[pt][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拼接方便后续处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15308, 127)\n"
     ]
    }
   ],
   "source": [
    "pt = pts[5]\n",
    "total_data = np.array(eeg[pt][0])\n",
    "total_label = np.array(audio[pt][0])\n",
    "for i in range(len(eeg[pt])):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    total_data = np.concatenate((total_data,eeg[pt][i]),axis=0)\n",
    "    total_label = np.concatenate((total_label,audio[pt][i]),axis=0)\n",
    "print(total_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z均值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13777, 127)\n",
      "[10.53307705 11.41864517 12.2387321  12.36208222 11.59930787  9.83395343\n",
      " 10.03693948 10.57370836  9.92624195  8.90767481  7.49765081  6.11109069\n",
      "  5.80136929  6.32955009  6.65738444  7.41547172  7.0842294   5.53498275\n",
      "  6.57884064  5.8545331   5.59856505  5.09560521  2.57025279]\n",
      "[ 9.77679059 10.86393702 11.69747238 11.98998318 12.07730874 10.92936929\n",
      " 11.73153468 10.9757972  10.92168166 10.55018863 10.09834642  9.85315717\n",
      " 10.64005122  9.93200347  8.93915556  8.13008183  7.36004233  6.39690863\n",
      "  7.23925989  6.84910403  6.5176429   5.59149135  3.35894218]\n"
     ]
    }
   ],
   "source": [
    "# 随机打乱数据索引\n",
    "indices = np.random.permutation(total_data.shape[0])\n",
    "\n",
    "# 计算划分索引\n",
    "split_index = int(total_data.shape[0] * 0.9)\n",
    "\n",
    "# 划分数据集\n",
    "train_indices = indices[:split_index]\n",
    "test_indices = indices[split_index:]\n",
    "\n",
    "# 获取训练集和测试集数据\n",
    "train_data = total_data[train_indices]\n",
    "train_label = total_label[train_indices]\n",
    "test_data = total_data[test_indices]\n",
    "test_label = total_label[test_indices]\n",
    "\n",
    "train_data_mean = np.mean(train_data)\n",
    "train_data_std = np.std(train_data)\n",
    "\n",
    "train_label_mean = np.mean(train_label)\n",
    "train_label_std = np.std(train_label)\n",
    "\n",
    "\n",
    "train_data = (train_data-train_data_mean)/train_data_std\n",
    "test_data = (test_data-train_data_mean)/train_data_std\n",
    "\n",
    "# train_label = (train_label-train_label_mean)/train_label_std\n",
    "# test_label = (test_label- train_label_std)/train_label_std\n",
    "\n",
    "print(train_data.shape)\n",
    "# print(train_data[0])\n",
    "# print(train_data[1])\n",
    "print(train_label[0])\n",
    "print(train_label[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'transformer' from 'd:\\\\workspace\\\\research\\\\SingleWordProductionDutch\\\\transformer.py'>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import imp\n",
    "import transformer\n",
    "imp.reload(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 23\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 500\n",
    "print_interval = 5\n",
    "lr = 0.00002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "input_dim = total_data.shape[1]\n",
    "output_dim = total_label.shape[1]\n",
    "d_model = 256\n",
    "nhead = 4\n",
    "n_layer =6\n",
    "tensor_type = torch.cuda.FloatTensor\n",
    "\n",
    "# log_write = open(f\"./log/log_{pt}.txt\", \"w\") \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = transformer.Model(\n",
    "    input_dim=input_dim,\n",
    "    output_dim=output_dim,\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    n_layer=n_layer\n",
    ").to(device)\n",
    "\n",
    "# criterion = nn.MSELoss(reduction='mean').to(device)\n",
    "criterion = nn.L1Loss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr,betas=(b1,b2))\n",
    "\n",
    "print(input_dim,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.from_numpy(train_data)\n",
    "train_label = torch.from_numpy(train_label)\n",
    "test_data = torch.from_numpy(test_data).to(device).type(tensor_type)\n",
    "test_label = torch.from_numpy(test_label).to(device).type(tensor_type)\n",
    "\n",
    "train_dataset = TensorDataset(train_data,train_label)\n",
    "# test_dataset = TensorDataset(test_data,test_label)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True,pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(f'./logs/{pt}')\n",
    "\n",
    "writer.add_graph(model,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 500/500 [11:09<00:00,  1.34s/it, average loss=0.41, test loss=0.42626652] \n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm.trange(epochs, desc=f\"Epochs\")\n",
    "\n",
    "for e in pbar:\n",
    "    model.train()\n",
    "    aver_loss= 0\n",
    "    for _, (data, label) in enumerate(train_dataloader):\n",
    "        data = data.to(device)\n",
    "        data = data.type(tensor_type)\n",
    "        label = label.to(device)\n",
    "        label = label.type(tensor_type)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, label)\n",
    "        aver_loss+=loss.detach().cpu().numpy()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # if (e + 1) % print_interval == 0:\n",
    "    model.eval()\n",
    "    test_outputs = model(test_data)\n",
    "    test_loss = criterion(test_outputs, test_label).detach().cpu().numpy()\n",
    "    aver_loss = aver_loss/len(train_dataloader)\n",
    "    pbar.set_postfix({'average loss':aver_loss,'test loss':test_loss})\n",
    "    writer.add_scalar('average loss',aver_loss,e)\n",
    "    writer.add_scalar('test loss',test_loss,e)\n",
    "    # log_write.write(f'{e}\\t\\t{aver_loss}\\t\\t{test_loss}\\n')\n",
    "    # log_write.flush()\n",
    "\n",
    "torch.save(model.state_dict(), f'./res/{pt}_model.pth')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.961931  11.13282   10.161477  ...  7.2029147  7.150252   5.8536253]\n",
      " [ 6.4487047  7.6826696  7.240362  ...  6.1469207  6.1527495  5.042369 ]\n",
      " [ 9.669281  10.917458  10.671871  ...  4.135633   3.9088254  2.5275223]\n",
      " ...\n",
      " [ 9.577301  10.978248   9.712202  ...  5.289433   5.005707   3.307084 ]\n",
      " [10.475774  11.653199  11.601434  ...  7.5067387  6.7015386  4.6305666]\n",
      " [10.5554905 11.91072   11.475509  ...  7.569194   7.035995   5.274171 ]] [[ 9.479337  11.043268   9.720101  ...  6.7097225  7.0673895  6.117388 ]\n",
      " [ 6.017125   7.5928135  7.3243685 ...  5.7848377  6.012065   4.6821566]\n",
      " [ 9.51248   10.848118  11.4815855 ...  4.1983466  3.8367896  2.5746264]\n",
      " ...\n",
      " [10.177409  11.322115   9.745621  ...  5.5244346  4.768065   3.2150702]\n",
      " [11.107904  12.544627  11.612778  ...  6.9679823  6.0626163  3.8187833]\n",
      " [10.546551  11.719819  12.143424  ...  7.2116675  6.4691424  4.6362104]]\n"
     ]
    }
   ],
   "source": [
    "test_outputs = model(test_data)\n",
    "print(test_outputs.detach().cpu().numpy(),test_label.detach().cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
