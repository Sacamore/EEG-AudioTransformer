# sEEG重建语音总结



## 问题描述
通过使用颅内脑电数据，进行时同的语音信号重构


## 面临问题
对于颅内脑电数据，面临着如下问题：
- 空间特异性：颅内电极根据实际医疗位置进行植入，缺乏有效利用电极间相对位置的手段，而且电极位置可能与任务目标无关；
- 局部性：颅内电极收集插入电极周围的一小部分电信号（电极周围的强电信号会掩盖弱电信号）；


对于语音数据，面临着如下问题：
- 语音具有高度特异性：根据男性、女性、年龄等因素，语音特征存在不同


对于数据集，面临着如下问题：
- 数据集少：公开的颅内脑电-语音数据集我目前仍然只有Verwort等人的荷兰语数据集，许多文章既不公开使用的数据集，也不公开代码。
- 数据量小：该荷兰语数据集包含10名受试者，每名受试者有300秒的脑电-语音数据，其中单词发声部分仅有70秒。
- 数据不具有重复性：该荷兰语数据集中每位患者朗读的单词为从词库中随机抽取，几乎不包含重复的单词，相较于其他基于脑电的单词分类任务，其几乎只能做音素的分类和语音合成
- 音素不平衡及难以划分区间：频次最高的音素总计有400多次，频次最低的音素总计有3次，数据不平衡，部分音素会有吞音的现象，而且较为短促，难以划分区间。

对于评判标准，面临着如下问题：
- 评判标准不合理：PCC是较为普遍的一种评判方式，许多文章以它为指标，但是它与语音的重建效果并不具有太强的关联性
- 评分标准不同：并不具有一个统一的数据处理方法，因此得到的评分也不统一，可以通过不同的数据处理方法获得10%的pcc提升，但实际效果下降


## 文章分析
对于颅内脑电与语音的研究大致可以分为如下几个方向：
- 基于脑电进行单词的分类
    - 基于脑电进行音素的分类，然后推测单词
    - 基于脑电进行发声动作的分类，再推测单词
- 基于脑电直接进行语音的重构
    - 重构语音生成方式，减少参数量(使用预训练大模型、)
    - 深度学习提取特征


## 实践方案
1. 使用MFA对音素进行标注，尝试对音素进行分类
    - 即使手动进行调整，标注区间也偏差过大，且音素不均衡
2. 使用Transformer的Encoder结构对脑电时序输入的特征捕捉直接进行语音合成
3. 使用多级CNN的ResNet对脑电进行特征提取直接进行语音合成
4. 先使用VQVAE实现一个语音自编码器学习语音特征码本，再提取特征并进行分类，将合成语音的任务转换为分类任务
    - 参考了去年四月的那篇nature的想法，意图是使用自编码器降低重建语音所需参数量，使用码本降低从脑电重建语音的难度（即从回归任务转变为分类任务）
5. 使用对抗的方式将脑电与语音特征进行对齐
    - 参考了多模态融合的方法，原本的VQVAE方法总是难以将脑电信号特征映射到语音特征上，于是就考虑从训练时就进行对齐。


其中包含多次调整模型结构及参数，以及尝试采用不同的神经网络模型。（这也是神经网络的弊端所在，在不同的模型参数设置下可能会有10%以上的不同）  


除此之外还进行了两次代码的重写，以便整理项目，使结构更明确高效。


## 结论
我认为该课题跟受试者关联性极强，如果电极位置合适，那么线性模型就能解码语音（如受试者3、6），效果与深度学习区别不大；如果电极位置不合适，那么怎么调都十分困难（如受试者1、5）。深度学习方法能改善部分，但似乎不能起到决定性的作用，无法实现很高的提升。


## 可能的改进方向
- 融合对抗与VQVAE，让其在特征对齐的同时进行聚类
- 在VQVAE上实现动态的更新、融合码本中的向量，实现更好的分类效果
- 结合脑部解剖知识，对同一脑区的电极一起进行分析（汤）