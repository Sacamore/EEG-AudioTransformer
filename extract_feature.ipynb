{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.signal\n",
    "import scipy.io\n",
    "import utils\n",
    "\n",
    "from pynwb import NWBHDF5IO\n",
    "from tqdm import tqdm\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "公共变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "winL = 0.05\n",
    "frameshift = 0.01\n",
    "modelOrder = 4\n",
    "stepSize = 5\n",
    "path_bids = r'./SingleWordProductionDutch-iBIDS'\n",
    "feat_path = r'./feat'\n",
    "result_path = r'./res'\n",
    "# pts = ['sub-%02d'%i for i in range(1,11)]\n",
    "participants = pd.read_csv(os.path.join(path_bids,'participants.tsv'), delimiter='\\t')\n",
    "pts = participants['participant_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据预处理\n",
    "- eeg数据\n",
    "- 语音音频数据\n",
    "- 语音文本数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:51<00:00,  5.17s/it]\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(os.path.join(feat_path), exist_ok=True)\n",
    "for p_id, pt in enumerate(tqdm(pts)):\n",
    "    os.makedirs(os.path.join(feat_path,f'{pt}'), exist_ok=True)\n",
    "    #Load data\n",
    "    io = NWBHDF5IO(os.path.join(path_bids,pt,'ieeg',f'{pt}_task-wordProduction_ieeg.nwb'), 'r')\n",
    "    nwbfile = io.read()\n",
    "    #sEEG\n",
    "    eeg = nwbfile.acquisition['iEEG'].data[:]\n",
    "    eeg_sr = 1024\n",
    "    #audio\n",
    "    audio = nwbfile.acquisition['Audio'].data[:]\n",
    "    audio_sr = 48000\n",
    "    #words (markers)\n",
    "    words = nwbfile.acquisition['Stimulus'].data[:]\n",
    "    words = np.array(words, dtype=str)\n",
    "    io.close()\n",
    "    #channels\n",
    "    channels = pd.read_csv(os.path.join(path_bids,pt,'ieeg',f'{pt}_task-wordProduction_channels.tsv'), delimiter='\\t')\n",
    "    channels = np.array(channels['name'])\n",
    "    \n",
    "    #Extract HG features\n",
    "    feat = utils.extractHG(eeg,eeg_sr, windowLength=winL,frameshift=frameshift)\n",
    " \n",
    "\n",
    "    #Process Audio\n",
    "    target_SR = 16000\n",
    "    audio = scipy.signal.decimate(audio,int(audio_sr / target_SR))\n",
    "    audio_sr = target_SR\n",
    "    scaled = np.int16(audio/np.max(np.abs(audio)) * 32767)\n",
    "    # scaled[np.abs(scaled)<1000] = 0\n",
    "    record_words = utils.dict4wav(words)\n",
    "    os.makedirs(os.path.join(feat_path,f'{pt}','audio'), exist_ok=True)\n",
    "    # os.makedirs(os.path.join(path_output,f'{pt}','result'), exist_ok=True)\n",
    "    for i in range(len(record_words)):\n",
    "        audio_length = int(len(scaled)/len(record_words))\n",
    "        eeg_length = int(len(eeg)/len(record_words))\n",
    "        word_length = 1\n",
    "        scipy.io.wavfile.write(os.path.join(feat_path,f'{pt}','audio',f'{pt}_{i}.wav'),audio_sr,scaled[i*audio_length:(i+1)*audio_length])\n",
    "        np.save(os.path.join(feat_path,f'{pt}','audio',f'{pt}_{i}.npy'), eeg[i*eeg_length:(i+1)*eeg_length])\n",
    "        with open(os.path.join(feat_path,f'{pt}','audio',f'{pt}_{i}.lab'), \"w\", encoding=\"utf-8\") as file:\n",
    "            for word in record_words[i*word_length:(i+1)*word_length]:\n",
    "                file.write(\"%s\\n\" % word)\n",
    "    #Extract spectrogram\n",
    "    melSpec = utils.extractMelSpecs(scaled,audio_sr,windowLength=winL,frameshift=frameshift)\n",
    "    #Align to EEG features\n",
    "    words = utils.downsampleLabels(words,eeg_sr,windowLength=winL,frameshift=frameshift)\n",
    "    #adjust length (differences might occur due to rounding in the number of windows)\n",
    "    if melSpec.shape[0]!=feat.shape[0]:\n",
    "        tLen = np.min([melSpec.shape[0],feat.shape[0]])\n",
    "        melSpec = melSpec[:tLen,:]\n",
    "        feat = feat[:tLen,:]\n",
    "\n",
    "    #Create feature names by appending the temporal shift \n",
    "    feature_names = utils.nameVector(channels[:,None], modelOrder=modelOrder)\n",
    "\n",
    "    #Save everything\n",
    "    np.save(os.path.join(feat_path,f'{pt}',f'{pt}_feat.npy'), feat)\n",
    "    np.save(os.path.join(feat_path,f'{pt}',f'{pt}_procWords.npy'), words)\n",
    "    np.save(os.path.join(feat_path,f'{pt}',f'{pt}_spec.npy'), melSpec)\n",
    "    np.save(os.path.join(feat_path,f'{pt}',f'{pt}_feat_names.npy'), feature_names)\n",
    "    \n",
    "    \n",
    "    with open(os.path.join(feat_path,f'{pt}',f'{pt}_words.txt'), \"w\", encoding=\"utf-8\") as file:\n",
    "        for word in record_words:\n",
    "            file.write(\"%s\\n\" % word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用mfa标注语音数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [16:19<00:00, 97.93s/it]\n"
     ]
    }
   ],
   "source": [
    "for p_id, pt in enumerate(tqdm(participants['participant_id'])):\n",
    "    pass# subprocess.run(['mfa', 'align',os.path.join(feat_path,f'{pt}','audio'),'dutch_cv','dutch_cv',os.path.join(feat_path,f'{pt}','audio'),'--clean'], stdout=subprocess.PIPE, text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理语音-音标-eeg数据，并按照音标以npy保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 0.6\n",
      "min length: 0.02600348744905001\n"
     ]
    }
   ],
   "source": [
    "phones_output_path = os.path.join(feat_path,'phones')\n",
    "os.makedirs(phones_output_path, exist_ok=True)\n",
    "big_phones_log = open('./log/big_phones.txt','w')\n",
    "small_phones_log = open('./log/small_phones.txt','w')\n",
    "maxlength = 0\n",
    "minlength = 999\n",
    "big_phones = 0\n",
    "small_phones = 0\n",
    "for pt in pts:\n",
    "    word_count = 0\n",
    "    with open(os.path.join(feat_path,f'{pt}',f'{pt}_words.txt'), 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        words = text.split()\n",
    "        word_count = len(words)\n",
    "    for i in range(word_count):\n",
    "        phones_info = utils.readTextGridPhones(feat_path,pt,i)\n",
    "        audio_sample_rate,audio_data = scipy.io.wavfile.read(os.path.join(feat_path,f'{pt}','audio',f'{pt}_{i}.wav'))\n",
    "        eeg_sample_rate = 1024\n",
    "        eeg_data = np.load(os.path.join(feat_path,f'{pt}','audio',f'{pt}_{i}.npy'))\n",
    "        for phone_info in phones_info:\n",
    "            phone_length = phone_info['end_time']-phone_info['start_time']\n",
    "            maxlength = max(maxlength,phone_length)\n",
    "            minlength = min(minlength,phone_length)\n",
    "            phone_info['audio'] = audio_data[int(phone_info['start_time']*audio_sample_rate):int(phone_info['end_time']*audio_sample_rate)]\n",
    "            phone_info['eeg'] = eeg_data[int(phone_info['start_time']*eeg_sample_rate):int(phone_info['end_time']*eeg_sample_rate)]\n",
    "            if not os.path.exists(os.path.join(phones_output_path,phone_info[\"label\"])):\n",
    "                os.makedirs(os.path.join(phones_output_path,phone_info[\"label\"]))\n",
    "            count = 1\n",
    "            save_name = f'{pt}_{i}_{count}.npy'\n",
    "            while os.path.exists(os.path.join(phones_output_path,phone_info[\"label\"],save_name)):\n",
    "                count += 1\n",
    "                save_name = f'{pt}_{i}_{count}.npy'\n",
    "            if phone_length > 0.6:\n",
    "                big_phones_log.write(f'{pt}_{i}_{phone_info[\"label\"]}_{count} : {phone_length}\\n')\n",
    "                big_phones += 1\n",
    "            elif phone_length < 0.025:\n",
    "                small_phones_log.write(f'{pt}_{i}_{phone_info[\"label\"]}_{count} : {phone_length}\\n')\n",
    "                small_phones += 1\n",
    "            else:\n",
    "                np.save(os.path.join(phones_output_path,phone_info[\"label\"],save_name),phone_info)\n",
    "print('max length:',maxlength)\n",
    "print('min length:',minlength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照人保存语音数据\n",
    "- 相当于滤去无声、杂音的纯语音数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_output_path = os.path.join(feat_path,'words')\n",
    "os.makedirs(words_output_path, exist_ok=True)\n",
    "for pt in pts:\n",
    "    if not os.path.exists(os.path.join(words_output_path,pt)):\n",
    "        os.makedirs(os.path.join(words_output_path,pt))\n",
    "    word_count = 0\n",
    "    with open(os.path.join(feat_path,f'{pt}',f'{pt}_words.txt'), 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        words = text.split()\n",
    "        word_count = len(words)\n",
    "    for i in range(word_count):\n",
    "        word_info = utils.readTextGridWords(feat_path,pt,i)\n",
    "        audio_sample_rate,audio_data = scipy.io.wavfile.read(os.path.join(feat_path,f'{pt}','audio',f'{pt}_{i}.wav'))\n",
    "        eeg_sample_rate = 1024\n",
    "        eeg_data = np.load(os.path.join(feat_path,f'{pt}','audio',f'{pt}_{i}.npy'))\n",
    "        word_info['audio'] = audio_data[int(word_info['start_time']*audio_sample_rate):int(word_info['end_time']*audio_sample_rate)]\n",
    "        word_info['eeg'] = eeg_data[int(word_info['start_time']*eeg_sample_rate):int(word_info['end_time']*eeg_sample_rate)]\n",
    "        # save_name = f'{word_info[\"label\"]}.npy'\n",
    "        save_name = f'{i}.npy'\n",
    "        np.save(os.path.join(words_output_path,pt,save_name),word_info)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
